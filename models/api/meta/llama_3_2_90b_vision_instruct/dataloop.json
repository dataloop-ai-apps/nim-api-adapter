{
  "name": "nim-api-llama3-2-90b-vision-instruct-meta",
  "displayName": "llama-3.2-90b-vision-instruct",
  "version": "0.3.19",
  "scope": "public",
  "description": "Cutting-edge vision-language model exceling in high-quality reasoning from images.",
  "attributes": {
    "Hub": [
      "Nvidia",
      "Dataloop"
    ],
    "Provider": "Meta",
    "Deployed By": "NVIDIA",
    "Category": [
      "Model",
      "NIM"
    ],
    "Gen AI": "LMM",
    "Media Type": [
      "Image",
      "Text",
      "Multi Modal"
    ],
    "NLP": "Conversational"
  },
    "codebase": {
    "type": "git",
    "gitUrl": "https://github.com/dataloop-ai-apps/nim-api-adapter",
    "gitTag": "0.3.19"
  },
  "components": {
    "computeConfigs": [
      {
        "name": "nim-api-deploy",
        "driverId": "us-faas",
        "runtime": {
          "podType": "regular-xs",
          "concurrency": 10,
          "runnerImage": "gcr.io/viewo-g/piper/agent/runner/cpu/nim-api:0.1.10",
          "autoscaler": {
            "type": "rabbitmq",
            "minReplicas": 0,
            "maxReplicas": 2
          }
        }
      }
    ],
    "modules": [
      {
        "name": "nim-api-module",
        "entryPoint": "models/api/custom_model_adapter.py",
        "className": "CustomModelAdapter",
        "computeConfig": "nim-api-deploy",
        "description": "llama3.2 90b instruct NIM API Adapter",
        "integrations": [
          "dl-ngc-api-key"
        ],
        "initInputs": [
          {
            "type": "Model",
            "name": "model_entity"
          }
        ],
        "functions": [
          {
            "name": "predict_items",
            "input": [
              {
                "type": "Item[]",
                "name": "items",
                "description": "List of items to run inference on"
              }
            ],
            "output": [
              {
                "type": "Item[]",
                "name": "items",
                "description": "The same input images for prediction."
              },
              {
                "type": "Annotation[]",
                "name": "annotations",
                "description": "The predicted annotations."
              }
            ],
            "displayName": "Predict Items",
            "displayIcon": "",
            "description": "NIM API llama3.2 predict items"
          }
        ]
      }
    ],
    "models": [
      {
        "name": "llama-3-2-90b-vision-instruct",
        "moduleName": "nim-api-module",
        "scope": "project",
        "status": "pre-trained",
        "configuration": {
          "nim_model_name": "meta/llama-3.2-90b-vision-instruct",
          "nim_invoke_url": "gr/meta/llama-3.2-90b-vision-instruct/chat/completions",
          "system_prompt": "You are a helpful and a bit cynical assistant. Give relevant and short answers, if you dont know the answer just say it, dont make up an answer",
          "max_tokens": 1024,
          "temperature": 0.2,
          "top_p": 0.7,
          "seed": 0,
          "stream": true
        },
        "description": "The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models."
      }
    ]
  }
}